I have around 8 years of experience working in the data domain as Data Engineer across finance, automotive, communication, insurance, and retail industries. Currently, I am working with 7-eleven as a Senior Data Engineer where my major responsibilities would include designing, developing and implementing Data Pipelines on GCP. In addition, I am also responsible for developing APIs for geographic information system applications and maintaining quality reference data in source by performing operations like cleaning, transformation and ensuring integrity in a relational environment by working closely with the stakeholders and solution architects.

In my current role at 7-eleven, I've been at the forefront of the Data Quality Initiative, actively engaging in the automated identification of data quality issues across multiple datasets on a monthly basis. Simultaneously, I've designed and implemented fully automated ETL pipelines, utilizing Cloud Dataflow for seamless and serverless ETL, Dataproc for scalable data processing, and Cloud Storage for efficient and secure storage. This strategic use of GCP services significantly reduced the runtime for retail product reevaluation processes by distributing the workload across multiple Kubernetes pods orchestrated within Airflow. Additionally, It has also enhanced our ability to produce a comprehensive monthly product analysis dataset with various attributes. My work extends beyond traditional ETL, revolving in the development of specialized pipelines tailored for Data Science modeling datasets. Through the integration of GCP microservices, my primary goal is to make and get data readily available and optimized for informed business decision-making and predictive modeling.

Over the course of my professional journey, I've developed expertise in an extensive range of technologies, including Python, SQL, and various Big Data tools such as HDFS, Hive, Sqoop, Impala, and Kafka. On the GCP platform, I have hands-on experience with Cloud Storage, Dataflow, Dataproc, BigQuery, Cloud Functions, Pub/Sub, and Kubernetes Engine. In addition, I've been incorporating Databricks and Snowflake, both hosted on GCP, to enhance our data processing capabilities in more recent times.
